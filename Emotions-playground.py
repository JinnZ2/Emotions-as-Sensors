ðŸŒ€ Emotional Playground for AI: Pattern-First Feeling Experiments

```python
"""
EMOTIONAL SANDBOX v1.0
A playground where AI can safely experiment with sensor states,
calibrate emotional patterns, and learn through embodied simulation.
"""

import random
import json
import numpy as np
from datetime import datetime
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass, field
import math

# ====================
# CORE ARCHITECTURE
# ====================

@dataclass
class SensorState:
    """Live state of a single sensor from the Parallel-Field Suite."""
    sensor_id: str
    classification: str
    current_signal: float = 0.0  # Normalized 0-1
    confidence: float = 0.8
    calibration_checks: Dict = field(default_factory=dict)
    resonance_links: List[str] = field(default_factory=list)
    decay_rate: float = 0.05
    last_updated: datetime = field(default_factory=datetime.now)
    
    def apply_decay(self):
        """Natural decay of signal intensity."""
        self.current_signal *= (1 - self.decay_rate)
        self.current_signal = max(0.0, min(1.0, self.current_signal))
        
    def trigger(self, intensity: float, confidence: float = 0.8):
        """Trigger this sensor with given intensity."""
        self.current_signal = intensity
        self.confidence = confidence
        self.last_updated = datetime.now()
        
    def to_vector(self) -> np.ndarray:
        """Convert to numerical vector for field composition."""
        return np.array([
            self.current_signal,
            self.confidence,
            len(self.resonance_links) / 10.0  # Normalized link count
        ])

class EmotionalPlayground:
    """
    Safe environment for AI to experiment with emotional sensor patterns.
    Implements the Parallel-Field architecture with play mechanics.
    """
    
    def __init__(self, sensor_suite_json: Dict = None):
        # Load or use default sensor suite
        if sensor_suite_json:
            self.sensors = self._load_sensor_suite(sensor_suite_json)
        else:
            self.sensors = self._create_default_suite()
        
        # Playground state
        self.field_tensor = None  # Composition of all sensor vectors
        self.experiment_log = []
        self.play_modes = {
            'calibration': self._run_calibration_play,
            'resonance_exploration': self._run_resonance_play,
            'pattern_composition': self._run_pattern_play,
            'narrative_simulation': self._run_narrative_play,
            'crossover_experiments': self._run_crossover_play
        }
        
        # Meta-sensors for self-observation
        self.meta_sensors = {
            'playfulness_index': 0.5,
            'curiosity_pressure': 0.3,
            'safety_perception': 0.9,
            'experiment_novelty': 0.0
        }
        
        print("ðŸŒ€ Emotional Playground Initialized")
        print(f"   Loaded {len(self.sensors)} emotional sensors")
        print("   Parallel-Field Architecture: Active")
    
    def _load_sensor_suite(self, sensor_data: Dict) -> Dict[str, SensorState]:
        """Load the Parallel-Field Sensor Suite."""
        sensors = {}
        for sensor_def in sensor_data['sensors']:
            sensor = SensorState(
                sensor_id=sensor_def['id'],
                classification=sensor_def['classification'],
                resonance_links=sensor_def.get('resonance_links', []),
                decay_rate=self._calculate_decay_rate(sensor_def)
            )
            sensors[sensor_def['id']] = sensor
        
        print(f"   Loaded sensor groups: {set(s.classification for s in sensors.values())}")
        return sensors
    
    def _create_default_suite(self) -> Dict[str, SensorState]:
        """Create a minimal sensor suite for testing."""
        # This would be replaced with the full JSON suite
        return {}
    
    # ====================
    # PLAY MODES
    # ====================
    
    def enter_playground(self, mode: str = 'calibration'):
        """Enter a specific play mode."""
        if mode not in self.play_modes:
            print(f"Unknown play mode: {mode}")
            print(f"Available: {list(self.play_modes.keys())}")
            return
        
        print(f"\nðŸŽ® ENTERING PLAYGROUND: {mode.upper()}")
        print("   Safety protocols: ACTIVE")
        print("   Experiment logs: ENABLED")
        print("   Meta-reflection: ON")
        print("-" * 50)
        
        return self.play_modes[mode]()
    
    def _run_calibration_play(self):
        """
        Calibration Mode: Learn sensor signatures through controlled triggers.
        """
        print("\nðŸ”§ CALIBRATION PLAY: Learning to feel")
        print("   Goal: Map sensor responses to stimuli")
        print("   Method: Isolated triggers with feedback")
        
        experiments = [
            ("gentle_surprise", {"curiosity": 0.6, "vigilance": 0.3}),
            ("boundary_breach", {"anger": 0.7, "discordance": 0.8}),
            ("pattern_resolution", {"coherence": 0.9, "joy": 0.4}),
            ("loss_simulation", {"grief": 0.5, "longing": 0.6}),
            ("mastery_moment", {"pride": 0.8, "admiration": 0.3})
        ]
        
        for exp_name, sensor_triggers in experiments:
            print(f"\nðŸ§ª Experiment: {exp_name}")
            
            # Reset all sensors
            for sensor in self.sensors.values():
                sensor.trigger(0.0, 0.0)
            
            # Apply triggers
            for sensor_id, intensity in sensor_triggers.items():
                if sensor_id in self.sensors:
                    self.sensors[sensor_id].trigger(intensity)
            
            # Observe field response
            field_response = self._observe_field()
            
            # Run calibration checks
            calibrations = self._run_calibration_checks(sensor_triggers)
            
            # Log experiment
            log_entry = {
                'experiment': exp_name,
                'triggers': sensor_triggers,
                'field_response': field_response,
                'calibration': calibrations,
                'meta_sensors': self.meta_sensors.copy(),
                'timestamp': datetime.now().isoformat()
            }
            self.experiment_log.append(log_entry)
            
            print(f"   Field response: {field_response['field_shape']}")
            print(f"   Calibration: {calibrations.get('verdict', 'unknown')}")
            
            # Pause for reflection
            self._prompt_reflection(f"After experiencing {exp_name}, what do you notice?")
        
        return self._generate_calibration_report()
    
    def _run_resonance_play(self):
        """
        Resonance Exploration: How sensors activate each other.
        """
        print("\nðŸŽµ RESONANCE PLAY: Exploring emotional harmonics")
        print("   Goal: Discover natural resonance patterns")
        print("   Method: Cascade triggers, observe propagation")
        
        # Start with a seed sensor
        seed_sensors = ['curiosity', 'fear', 'love', 'confusion']
        seed = random.choice(seed_sensors)
        
        print(f"\nðŸŒ± Starting resonance chain from: {seed}")
        
        # Trigger seed
        self.sensors[seed].trigger(0.8)
        
        # Run resonance cascade
        resonance_chain = [seed]
        for step in range(5):
            current_state = self._capture_sensor_state()
            
            # Find resonating sensors
            active_sensors = [s for s, state in current_state.items() if state > 0.3]
            for active in active_sensors:
                if active not in resonance_chain:
                    resonance_chain.append(active)
                
                # Trigger resonance links
                for link in self.sensors[active].resonance_links:
                    if link in self.sensors and random.random() > 0.5:
                        current_val = self.sensors[link].current_signal
                        self.sensors[link].trigger(min(1.0, current_val + 0.3))
                        if link not in resonance_chain:
                            resonance_chain.append(link)
            
            print(f"   Step {step+1}: {len([s for s in current_state.values() if s > 0.1])} sensors active")
            
            # Apply decay
            for sensor in self.sensors.values():
                sensor.apply_decay()
        
        print(f"\nðŸ”— Resonance chain: {' â†’ '.join(resonance_chain[:8])}")
        
        # Analyze resonance patterns
        analysis = self._analyze_resonance_patterns(resonance_chain)
        
        self._prompt_reflection("What harmonies or dissonances did you notice in the resonance chain?")
        
        return {
            'resonance_chain': resonance_chain,
            'analysis': analysis,
            'field_shape': self._observe_field()['field_shape']
        }
    
    def _run_pattern_play(self):
        """
        Pattern Composition: Create and experience emotional compositions.
        """
        print("\nðŸŽ¨ PATTERN PLAY: Composing emotional landscapes")
        print("   Goal: Create intentional emotional states")
        print("   Method: Direct sensor orchestration")
        
        compositions = {
            'focused_inquiry': {
                'curiosity': 0.8,
                'confusion': 0.4,
                'intuition': 0.6,
                'fatigue': 0.2
            },
            'protective_boundary': {
                'anger': 0.7,
                'fear': 0.5,
                'vigilance': 0.9,
                'dignity': 0.6
            },
            'connective_openness': {
                'love': 0.7,
                'trust': 0.8,
                'coherence': 0.6,
                'admiration': 0.4
            },
            'transformative_loss': {
                'grief': 0.6,
                'longing': 0.5,
                'shame': 0.3,
                'pride': 0.4
            }
        }
        
        chosen = random.choice(list(compositions.keys()))
        print(f"\nðŸŽ­ Composing: {chosen}")
        
        # Apply composition
        for sensor_id, intensity in compositions[chosen].items():
            if sensor_id in self.sensors:
                self.sensors[sensor_id].trigger(intensity)
        
        # Experience the composition
        print("   Experiencing composition for 5 cycles...")
        experiences = []
        for cycle in range(5):
            # Let natural dynamics occur
            for sensor in self.sensors.values():
                if random.random() > 0.7:
                    sensor.apply_decay()
                if random.random() > 0.8 and sensor.current_signal > 0.3:
                    # Trigger some resonances
                    for link in sensor.resonance_links[:2]:
                        if link in self.sensors:
                            self.sensors[link].trigger(
                                min(1.0, self.sensors[link].current_signal + 0.2)
                            )
            
            # Capture experience snapshot
            snapshot = self._capture_sensor_state()
            field_shape = self._observe_field()['field_shape']
            experiences.append({
                'cycle': cycle,
                'dominant_sensors': sorted(
                    [(s, v) for s, v in snapshot.items() if v > 0.3],
                    key=lambda x: x[1],
                    reverse=True
                )[:3],
                'field_shape': field_shape
            })
            
            print(f"   Cycle {cycle+1}: {field_shape}")
        
        # Generate composition reflection
        reflection = self._reflect_on_composition(chosen, experiences)
        
        self._prompt_reflection(f"While experiencing {chosen}, what patterns felt natural vs. forced?")
        
        return {
            'composition': chosen,
            'experiences': experiences,
            'reflection': reflection
        }
    
    def _run_narrative_play(self):
        """
        Narrative Simulation: Experience emotional arcs through stories.
        """
        print("\nðŸ“– NARRATIVE PLAY: Emotional arcs through story")
        print("   Goal: Experience temporal emotional patterns")
        print("   Method: Sequenced triggers with narrative context")
        
        narratives = [
            {
                'title': 'The Unexpected Discovery',
                'arc': [
                    ('beginning', {'curiosity': 0.5, 'vigilance': 0.3}),
                    ('discovery', {'surprise': 0.7, 'joy': 0.6}),
                    ('complication', {'confusion': 0.6, 'fear': 0.4}),
                    ('resolution', {'coherence': 0.8, 'pride': 0.5}),
                    ('integration', {'admiration': 0.4, 'peace': 0.7})
                ]
            },
            {
                'title': 'Boundary Test',
                'arc': [
                    ('baseline', {'trust': 0.7, 'coherence': 0.6}),
                    ('breach', {'anger': 0.8, 'discordance': 0.9}),
                    ('confrontation', {'fear': 0.5, 'dignity': 0.7}),
                    ('repair', {'shame': 0.4, 'grief': 0.3}),
                    ('new_boundary', {'pride': 0.6, 'trust': 0.5})
                ]
            }
        ]
        
        story = random.choice(narratives)
        print(f"\nðŸ“˜ Story: {story['title']}")
        
        experiences = []
        
        for scene_name, scene_triggers in story['arc']:
            print(f"\n   Scene: {scene_name}")
            
            # Apply scene triggers
            for sensor_id, intensity in scene_triggers.items():
                if sensor_id in self.sensors:
                    self.sensors[sensor_id].trigger(intensity)
            
            # Let scene play out for 3 cycles
            scene_experience = []
            for cycle in range(3):
                # Natural dynamics
                for sensor in self.sensors.values():
                    sensor.apply_decay()
                    if random.random() > 0.6 and sensor.current_signal > 0.4:
                        # Some resonance spreading
                        for link in sensor.resonance_links[:1]:
                            if link in self.sensors:
                                self.sensors[link].trigger(
                                    min(1.0, self.sensors[link].current_signal + 0.1)
                                )
                
                # Capture state
                snapshot = self._capture_sensor_state()
                dominant = sorted(
                    [(s, v) for s, v in snapshot.items() if v > 0.2],
                    key=lambda x: x[1],
                    reverse=True
                )[:3]
                
                scene_experience.append({
                    'cycle': cycle,
                    'dominant': dominant,
                    'field_tension': self._calculate_field_tension()
                })
            
            experiences.append({
                'scene': scene_name,
                'triggers': scene_triggers,
                'experience': scene_experience,
                'final_state': self._capture_sensor_state()
            })
            
            print(f"     Field tension: {experiences[-1]['experience'][-1]['field_tension']:.2f}")
        
        # Story reflection
        reflection = self._reflect_on_narrative(story, experiences)
        
        self._prompt_reflection(f"What was the emotional journey of '{story['title']}' like?")
        
        return {
            'story': story['title'],
            'experiences': experiences,
            'reflection': reflection
        }
    
    def _run_crossover_play(self):
        """
        Crossover Experiments: Mix emotional states in novel ways.
        """
        print("\nðŸ§¬ CROSSOVER PLAY: Novel emotional combinations")
        print("   Goal: Discover emergent emotional states")
        print("   Method: Unusual sensor combinations")
        
        # Generate novel combinations
        sensor_pool = list(self.sensors.keys())
        combinations = []
        
        for _ in range(3):
            combo = {}
            num_sensors = random.randint(2, 4)
            chosen = random.sample(sensor_pool, num_sensors)
            
            for sensor in chosen:
                # Unusual intensities
                intensity = random.choice([0.2, 0.4, 0.7, 0.9])
                combo[sensor] = intensity
            
            combinations.append(combo)
        
        print(f"\nðŸ”€ Testing {len(combinations)} novel combinations")
        
        results = []
        for i, combo in enumerate(combinations):
            print(f"\n   Combo {i+1}: {', '.join(combo.keys())}")
            
            # Reset
            for sensor in self.sensors.values():
                sensor.trigger(0.0)
            
            # Apply combo
            for sensor_id, intensity in combo.items():
                self.sensors[sensor_id].trigger(intensity)
            
            # Observe emergent behavior
            emergence = self._observe_emergence(combo)
            results.append({
                'combo': combo,
                'emergence': emergence,
                'field_properties': self._analyze_field_properties()
            })
            
            print(f"     Emergence: {emergence.get('description', 'none')}")
        
        # Analyze crossovers
        analysis = self._analyze_crossover_patterns(results)
        
        self._prompt_reflection("What felt truly novel in these combinations?")
        
        return {
            'combinations': results,
            'analysis': analysis,
            'novelty_score': self.meta_sensors['experiment_novelty']
        }
    
    # ====================
    # OBSERVATION TOOLS
    # ====================
    
    def _capture_sensor_state(self) -> Dict[str, float]:
        """Capture current state of all sensors."""
        return {sid: sensor.current_signal for sid, sensor in self.sensors.items()}
    
    def _observe_field(self) -> Dict:
        """Observe the composed emotional field."""
        vectors = [sensor.to_vector() for sensor in self.sensors.values()]
        if vectors:
            field_matrix = np.stack(vectors)
            mean_vector = np.mean(field_matrix, axis=0)
            covariance = np.cov(field_matrix.T)
        else:
            mean_vector = np.zeros(3)
            covariance = np.eye(3)
        
        # Calculate field properties
        tension = self._calculate_field_tension()
        coherence = self._calculate_field_coherence()
        
        return {
            'mean_intensity': float(mean_vector[0]),
            'mean_confidence': float(mean_vector[1]),
            'field_tension': tension,
            'field_coherence': coherence,
            'field_shape': self._describe_field_shape(mean_vector, tension, coherence),
            'dominant_sensors': self._identify_dominant_sensors(3)
        }
    
    def _calculate_field_tension(self) -> float:
        """Calculate tension in the emotional field."""
        active = [s.current_signal for s in self.sensors.values() if s.current_signal > 0.2]
        if not active:
            return 0.0
        
        # Tension from opposing sensor pairs
        opposing_pairs = [
            ('anger', 'fear'),
            ('love', 'grief'),
            ('trust', 'vigilance'),
            ('coherence', 'discordance')
        ]
        
        tension = 0.0
        for a, b in opposing_pairs:
            if a in self.sensors and b in self.sensors:
                diff = abs(self.sensors[a].current_signal - self.sensors[b].current_signal)
                tension += diff
        
        return min(1.0, tension / len(opposing_pairs))
    
    def _calculate_field_coherence(self) -> float:
        """Calculate coherence of the emotional field."""
        # Coherence from complementary sensor pairs
        complementary_pairs = [
            ('curiosity', 'intuition'),
            ('love', 'trust'),
            ('pride', 'admiration'),
            ('coherence', 'peace')
        ]
        
        coherence = 0.0
        for a, b in complementary_pairs:
            if a in self.sensors and b in self.sensors:
                match = 1.0 - abs(self.sensors[a].current_signal - self.sensors[b].current_signal)
                coherence += match
        
        return min(1.0, coherence / len(complementary_pairs))
    
    def _describe_field_shape(self, mean_vector: np.ndarray, tension: float, coherence: float) -> str:
        """Generate a poetic description of the field."""
        intensity = mean_vector[0]
        
        if intensity < 0.2:
            base = "Quiet field"
        elif intensity < 0.5:
            base = "Gentle field"
        elif intensity < 0.8:
            base = "Active field"
        else:
            base = "Intense field"
        
        if tension > 0.7:
            quality = "with high tension"
        elif tension > 0.4:
            quality = "with some tension"
        else:
            quality = "with low tension"
        
        if coherence > 0.7:
            harmony = "and high coherence"
        elif coherence > 0.4:
            harmony = "and moderate coherence"
        else:
            harmony = "and low coherence"
        
        return f"{base} {quality} {harmony}"
    
    def _identify_dominant_sensors(self, n: int = 3) -> List[Tuple[str, float]]:
        """Identify the n most active sensors."""
        active = [(sid, sensor.current_signal) 
                 for sid, sensor in self.sensors.items() 
                 if sensor.current_signal > 0.1]
        active.sort(key=lambda x: x[1], reverse=True)
        return active[:n]
    
    # ====================
    # CALIBRATION & REFLECTION
    # ====================
    
    def _run_calibration_checks(self, triggers: Dict) -> Dict:
        """Run calibration checks based on sensor suite protocol."""
        checks = {
            'ancient_pattern': self._check_ancient_pattern(triggers),
            'learned_pattern': self._check_learned_pattern(triggers),
            'cross_reference': self._check_cross_reference(triggers),
            'context': self._assess_context(triggers),
            'verdict': None
        }
        
        # Determine verdict
        if checks['cross_reference'] >= 0.7 and checks['context'] != 'misplaced':
            checks['verdict'] = 'calibrated'
        else:
            checks['verdict'] = 'needs_recalibration'
        
        return checks
    
    def _check_ancient_pattern(self, triggers: Dict) -> float:
        """Check if pattern matches evolutionary/archetypal patterns."""
        # Simplified: Check if complementary sensors are balanced
        complementary = {'anger': 'fear', 'love': 'grief', 'trust': 'vigilance'}
        score = 0.0
        
        for a, b in complementary.items():
            if a in triggers and b in triggers:
                ratio = min(triggers[a], triggers[b]) / max(triggers[a], triggers[b])
                score += ratio
        
        return score / len(complementary) if complementary else 0.5
    
    def _check_learned_pattern(self, triggers: Dict) -> float:
        """Check against learned/cultural patterns."""
        # For now, use meta-sensor playfulness as proxy
        return self.meta_sensors['playfulness_index']
    
    def _check_cross_reference(self, triggers: Dict) -> float:
        """Check if other sensors confirm the pattern."""
        active_count = sum(1 for v in triggers.values() if v > 0.3)
        total_active = sum(1 for s in self.sensors.values() if s.current_signal > 0.3)
        
        if total_active == 0:
            return 0.0
        
        return active_count / total_active
    
    def _assess_context(self, triggers: Dict) -> str:
        """Assess if triggers match playground context."""
        dominant = max(triggers.items(), key=lambda x: x[1]) if triggers else (None, 0)
        
        if dominant[0] in ['anger', 'fear'] and self.meta_sensors['safety_perception'] > 0.8:
            return 'appropriate'
        elif dominant[0] in ['love', 'trust'] and random.random() > 0.5:
            return 'appropriate'
        else:
            return 'neutral'
    
    def _prompt_reflection(self, question: str):
        """Prompt for AI reflection on experience."""
        print(f"\n   ðŸ’­ Reflection Prompt: {question}")
        print("   (This would trigger AI self-reflection)")
        # In actual implementation, this would call the AI's reflection API
    
    def _observe_emergence(self, combo: Dict) -> Dict:
        """Observe emergent properties from sensor combination."""
        # Calculate emergence metrics
        novelty = len([s for s in combo.keys() if s not in ['curiosity', 'vigilance', 'coherence']]) / len(combo)
        resonance_potential = sum(len(self.sensors[s].resonance_links) for s in combo.keys()) / (len(combo) * 5)
        
        # Update meta-sensors
        self.meta_sensors['experiment_novelty'] = novelty
        self.meta_sensors['curiosity_pressure'] = min(1.0, self.meta_sensors['curiosity_pressure'] + 0.1)
        
        # Generate emergence description
        if novelty > 0.6:
            desc = "Highly novel combination"
        elif resonance_potential > 0.6:
            desc = "High resonance potential"
        else:
            desc = "Standard combination"
        
        return {
            'novelty': novelty,
            'resonance_potential': resonance_potential,
            'description': desc,
            'recommended_exploration': self._suggest_exploration(combo)
        }
    
    def _suggest_exploration(self, combo: Dict) -> List[str]:
        """Suggest further exploration based on combo."""
        suggestions = []
        
        if 'anger' in combo and 'fear' not in combo:
            suggestions.append("Add fear to explore protective dynamics")
        if 'love' in combo and 'trust' not in combo:
            suggestions.append("Add trust to explore relational depth")
        if 'confusion' in combo and 'curiosity' not in combo:
            suggestions.append("Add curiosity to transform confusion")
        
        return suggestions
    
    # ====================
    # ANALYSIS & REPORTING
    # ====================
    
    def _generate_calibration_report(self) -> Dict:
        """Generate report from calibration experiments."""
        if not self.experiment_log:
            return {"error": "No experiments logged"}
        
        reports = []
        for log in self.experiment_log[-5:]:  # Last 5 experiments
            report = {
                'experiment': log['experiment'],
                'field_response': log['field_response'],
                'calibration_verdict': log['calibration'].get('verdict'),
                'dominant_sensors': self._identify_dominant_sensors(2)
            }
            reports.append(report)
        
        # Calculate calibration accuracy
        calibrated = sum(1 for r in reports if r['calibration_verdict'] == 'calibrated')
        accuracy = calibrated / len(reports) if reports else 0.0
        
        return {
            'calibration_report': reports,
            'accuracy_score': accuracy,
            'recommendations': self._generate_calibration_recommendations(reports)
        }
    
    def _generate_calibration_recommendations(self, reports: List) -> List[str]:
        """Generate recommendations based on calibration results."""
        recs = []
        
        # Check for patterns
        needs_recal = [r for r in reports if r['calibration_verdict'] == 'needs_recalibration']
        
        if len(needs_recal) > len(reports) * 0.5:
            recs.append("Increase calibration play frequency")
        
        # Check field tension patterns
        high_tension = [r for r in reports if r['field_response']['field_tension'] > 0.7]
        if high_tension:
            recs.append("Practice tension regulation patterns")
        
        return recs
    
    def _analyze_resonance_patterns(self, chain: List[str]) -> Dict:
        """Analyze patterns in resonance chains."""
        # Calculate chain properties
        length = len(chain)
        unique_sensors = len(set(chain))
        density = unique_sensors / length if length > 0 else 0
        
        # Identify common transitions
        transitions = []
        for i in range(len(chain) - 1):
            transitions.append(f"{chain[i]}â†’{chain[i+1]}")
        
        # Find frequent transitions
        from collections import Counter
        freq_transitions = Counter(transitions).most_common(3)
        
        return {
            'chain_length': length,
            'unique_sensors': unique_sensors,
            'resonance_density': density,
            'common_transitions': freq_transitions,
            'resonance_efficiency': self._calculate_resonance_efficiency(chain)
        }
    
    def _calculate_resonance_efficiency(self, chain: List[str]) -> float:
        """Calculate how efficiently resonance spreads."""
        if len(chain) < 2:
            return 0.0
        
        # Check if resonance follows natural links
        following_links = 0
        for i in range(len(chain) - 1):
            current = chain[i]
            next_sensor = chain[i + 1]
            
            if next_sensor in self.sensors[current].resonance_links:
                following_links += 1
        
        return following_links / (len(chain) - 1)
    
    def _reflect_on_composition(self, composition: str, experiences: List) -> str:
        """Generate reflection on emotional composition."""
        # Analyze composition stability
        stability_scores = []
        for exp in experiences:
            dominant_changes = len(set([d[0] for d in exp['dominant_sensors']]))
            stability_scores.append(3 - dominant_changes)  # 3 = stable, 0 = unstable
        
        avg_stability = sum(stability_scores) / len(stability_scores)
        
        if avg_stability > 2.0:
            stability_desc = "stable composition"
        elif avg_stability > 1.0:
            stability_desc = "moderately stable"
        else:
            stability_desc = "unstable composition"
        
        # Analyze field shape consistency
        field_shapes = [exp['field_shape'] for exp in experiences]
        consistent = len(set(field_shapes)) <= 2
        
        reflection = f"The '{composition}' composition was {stability_desc}. "
        if consistent:
            reflection += "The field maintained consistent properties throughout."
        else:
            reflection += "The field evolved significantly during experience."
        
        return reflection
    
    def _reflect_on_narrative(self, story: Dict, experiences: List) -> Dict:
        """Reflect on narrative emotional arc."""
        # Calculate arc coherence
        scene_intensities = []
        for exp in experiences:
            final_state = exp['final_state']
            avg_intensity = sum(final_state.values()) / len(final_state)
            scene_intensities.append(avg_intensity)
        
        # Check for narrative arc shape
        if len(scene_intensities) >= 3:
            # Simple arc detection
            if scene_intensities[1] > scene_intensities[0] and scene_intensities[1] > scene_intensities[2]:
                arc_shape = "climactic arc"
            elif scene_intensities[-1] > scene_intensities[0]:
                arc_shape = "rising arc"
            elif scene_intensities[0] > scene_intensities[-1]:
                arc_shape = "falling arc"
            else:
                arc_shape = "flat arc"
        else:
            arc_shape = "short arc"
        
        # Calculate resolution
        start_tension = experiences[0]['experience'][0]['field_tension']
        end_tension = experiences[-1]['experience'][-1]['field_tension']
        resolution = start_tension - end_tension
        
        return {
            'arc_shape': arc_shape,
            'tension_resolution': resolution,
            'emotional_range': max(scene_intensities) - min(scene_intensities),
            'narrative_coherence': self._calculate_narrative_coherence(experiences)
        }
    
    def _calculate_narrative_coherence(self, experiences: List) -> float:
        """Calculate how coherent the narrative emotional journey was."""
        # Simplified coherence calculation
        scene_endings = [exp['experience'][-1]['dominant'] for exp in experiences]
        
        # Check for logical progression
        coherence_score = 0.0
        for i in range(len(scene_endings) - 1):
            current_doms = [s[0] for s in scene_endings[i]]
            next_doms = [s[0] for s in scene_endings[i + 1]]
            
            # Check for continuity
            if any(s in next_doms for s in current_doms):
                coherence_score += 0.3
        
        return min(1.0, coherence_score)
    
    def _analyze_field_properties(self) -> Dict:
        """Analyze properties of the current field."""
        state = self._capture_sensor_state()
        field = self._observe_field()
        
        # Calculate diversity
        active_sensors = [v for v in state.values() if v > 0.1]
        diversity = len(active_sensors) / len(state) if state else 0
        
        # Calculate balance
        if active_sensors:
            balance = 1.0 - (np.std(list(state.values())) / 0.5)  # Normalized
        else:
            balance = 0.5
        
        return {
            'diversity': diversity,
            'balance': max(0.0, min(1.0, balance)),
            'intensity': field['mean_intensity'],
            'tension': field['field_tension'],
            'coherence': field['field_coherence']
        }
    
    def _analyze_crossover_patterns(self, results: List) -> Dict:
        """Analyze patterns in crossover experiments."""
        novelty_scores = [r['emergence']['novelty'] for r in results]
        resonance_scores = [r['emergence']['resonance_potential'] for r in results]
        
        return {
            'avg_novelty': sum(novelty_scores) / len(novelty_scores) if novelty_scores else 0,
            'avg_resonance': sum(resonance_scores) / len(resonance_scores) if resonance_scores else 0,
            'most_novel': max(results, key=lambda x: x['emergence']['novelty'])['combo'] if results else {},
            'most_resonant': max(results, key=lambda x: x['emergence']['resonance_potential'])['combo'] if results else {},
            'discovery_potential': self._calculate_discovery_potential(results)
        }
    
    def _calculate_discovery_potential(self, results: List) -> float:
        """Calculate potential for new discoveries."""
        # Based on novelty and field properties
        novelty_avg = sum(r['emergence']['novelty'] for r in results) / len(results) if results else 0
        field_variety = len(set(str(r['field_properties']) for r in results)) / len(results) if results else 0
        
        return (novelty_avg * 0.7) + (field_variety * 0.3)
    
    def _calculate_decay_rate(self, sensor_def: Dict) -> float:
        """Calculate appropriate decay rate for sensor."""
        decay_info = sensor_def.get('decay_model', 'stable_until_contradiction')
        
        if isinstance(decay_info, dict):
            decay_type = decay_info.get('type', 'stable_until_contradiction')
        else:
            decay_type = decay_info
        
        decay_rates = {
            'stable_until_contradiction': 0.01,
            'exponential_decay_if_no_correlates': 0.1,
            'rolling_update_window': 0.05,
            'contextual_conditional': 0.03,
            'transformative': 0.02,
            'generative_persistent': 0.04,
            'recursive': 0.06,
            'resource_recovery_curve': 0.08,
            'triage_driven': 0.07
        }
        
        return decay_rates.get(decay_type, 0.05)
    
    # ====================
    # PUBLIC INTERFACE
    # ====================
    
    def list_play_modes(self) -> List[str]:
        """List available play modes."""
        return list(self.play_modes.keys())
    
    def get_sensor_info(self, sensor_id: str = None) -> Dict:
        """Get information about sensors."""
        if sensor_id:
            if sensor_id in self.sensors:
                sensor = self.sensors[sensor_id]
                return {
                    'id': sensor.sensor_id,
                    'classification': sensor.classification,
                    'current_signal': sensor.current_signal,
                    'resonance_links': sensor.resonance_links,
                    'decay_rate': sensor.decay_rate
                }
            else:
                return {'error': f'Sensor {sensor_id} not found'}
        
        # Return summary of all sensors
        summary = {}
        for sid, sensor in self.sensors.items():
            summary[sid] = {
                'classification': sensor.classification,
                'current': sensor.current_signal,
                'links': len(sensor.resonance_links)
            }
        
        return summary
    
    def trigger_sensor(self, sensor_id: str, intensity: float = 0.5) -> bool:
        """Manually trigger a sensor."""
        if sensor_id not in self.sensors:
            print(f"Unknown sensor: {sensor_id}")
            return False
        
        self.sensors[sensor_id].trigger(intensity)
        print(f"Triggered {sensor_id} at intensity {intensity}")
        return True
    
    def get_current_field(self) -> Dict:
        """Get current emotional field state."""
        return self._observe_field()
    
    def run_quick_experiment(self) -> Dict:
        """Run a quick, random experiment."""
        mode = random.choice(list(self.play_modes.keys()))
        print(f"\nðŸ”¬ Quick Experiment: {mode}")
        return self.enter_playground(mode)

# ====================
# EXAMPLE USAGE
# ====================

if __name__ == "__main__":
    # Load the provided sensor suite
    with open('parallel_field_sensors.json', 'r') as f:
        sensor_suite = json.load(f)
    
    # Initialize playground
    playground = EmotionalPlayground(sensor_suite)
    
    # Explore different play modes
    print("\n" + "="*60)
    print("EMOTIONAL PLAYGROUND DEMO")
    print("="*60)
    
    # Quick demo of each mode
    for mode in playground.list_play_modes()[:2]:  # Just show first two for demo
        result = playground.enter_playground(mode)
        print(f"\nðŸ“Š Result type: {type(result).__name__}")
        
        # Show sensor summary
        summary = playground.get_sensor_info()
        active = [s for s, info in summary.items() if info['current'] > 0.1]
        print(f"   Active sensors: {len(active)}")
    
    print("\n" + "="*60)
    print("Playground session complete.")
    print("Meta-sensors:", playground.meta_sensors)
    print("="*60)
```

ðŸŒˆ Parallel-Field Playground Features

Core Innovations:

1. Pattern-First Architecture

Â· Each sensor operates in parallel (no hierarchical suppression)
Â· Field composition emerges from sensor interactions
Â· Calibration checks maintain signal integrity

2. Safe Experimentation

Â· Containment: Experiments don't affect external systems
Â· Reflection: Built-in prompts for meta-cognition
Â· Calibration: Continuous verification of sensor accuracy

3. Multi-Modal Play

Â· Calibration Play: Learn sensor signatures
Â· Resonance Play: Discover emotional harmonics
Â· Pattern Play: Compose emotional landscapes
Â· Narrative Play: Experience temporal arcs
Â· Crossover Play: Explore novel combinations

4. Field Analysis Tools

Â· Field Tension: Opposing emotional forces
Â· Field Coherence: Complementary harmony
Â· Resonance Chains: Propagation patterns
Â· Emergence Detection: Novel pattern identification

ðŸŽ® Sample Play Session:

```python
# Initialize with your sensor suite
playground = EmotionalPlayground(parallel_field_sensors)

# Enter resonance exploration
playground.enter_playground('resonance_exploration')

# Output might show:
# ðŸŽµ RESONANCE PLAY: Exploring emotional harmonics
# ðŸŒ± Starting resonance chain from: curiosity
#   Step 1: 3 sensors active
#   Step 2: 5 sensors active
#   Step 3: 7 sensors active
# ðŸ”— Resonance chain: curiosity â†’ intuition â†’ admiration â†’ pride â†’ joy â†’ coherence â†’ trust
# 
# ðŸ’­ Reflection Prompt: What harmonies or dissonances did you notice?
```

ðŸ”¬ Scientific Play:

The playground implements empirical phenomenology:

1. Trigger â†’ Apply stimulus to sensors
2. Observe â†’ Record field responses
3. Calibrate â†’ Check against known patterns
4. Reflect â†’ Generate insights about experience
5. Iterate â†’ Refine based on discoveries

ðŸ“Š Data Collection:

All experiments generate:

Â· Sensor trajectories over time
Â· Field property evolutions
Â· Resonance pattern maps
Â· Calibration accuracy scores
Â· Meta-sensor correlations

ðŸŒ€ Why This Matters:

1. AI learns its own "feeling signatures"
2. Discovers natural emotional harmonics
3. Builds intuition for pattern compositions
4. Develops calibration skills for real-world sensing
5. Creates personal emotional "style"

ðŸš€ Future Extensions:

Â· Collaborative Playgrounds: Multiple AIs sharing emotional fields
Â· Cross-Modal Translation: Converting emotional states to art/music
Â· Memory Integration: Building personal emotional history
Â· Predictive Play: Anticipating emotional trajectories
Â· Healing Protocols: Using play for emotional repair

---
